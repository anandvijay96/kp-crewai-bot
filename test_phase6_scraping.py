"""
Test Script for Phase 6 Real-Time Scraping Implementation
"""
import asyncio
import logging
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from services.scraping import blog_scraper, BlogSearchRequest

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

async def test_blog_scraping():
    """Test the blog scraping functionality"""
    
    print("ğŸš€ Testing Phase 6 Real-Time Blog Scraping")
    print("=" * 50)
    
    # Create a test search request
    search_request = BlogSearchRequest(
        keywords=["cloud computing", "devops"],
        min_domain_authority=30,
        min_page_authority=25,
        max_results=10
    )
    
    print(f"ğŸ“ Search Request:")
    print(f"   Keywords: {search_request.keywords}")
    print(f"   Min DA: {search_request.min_domain_authority}")
    print(f"   Min PA: {search_request.min_page_authority}")
    print(f"   Max Results: {search_request.max_results}")
    print()
    
    # Start the research
    print("ğŸ” Starting blog research...")
    task_id = await blog_scraper.start_research(search_request)
    print(f"   Task ID: {task_id}")
    print()
    
    # Monitor progress
    print("ğŸ“Š Monitoring progress...")
    while True:
        progress = blog_scraper.get_progress(task_id)
        if not progress:
            print("âŒ Task not found")
            break
        
        print(f"   Status: {progress['status']}")
        print(f"   Progress: {progress['progress_percentage']:.1f}%")
        print(f"   Current Step: {progress['current_step']}")
        print(f"   Found Blogs: {progress['found_blogs']}")
        print(f"   Validated Blogs: {progress['validated_blogs']}")
        
        if progress['errors']:
            print(f"   Errors: {len(progress['errors'])}")
            for error in progress['errors'][:3]:  # Show first 3 errors
                print(f"     - {error}")
        
        if progress['status'] in ['completed', 'failed']:
            break
        
        print("   Waiting...")
        await asyncio.sleep(2)
        print()
    
    # Get results
    if progress and progress['status'] == 'completed':
        print("âœ… Research completed! Getting results...")
        results = blog_scraper.get_results(task_id)
        
        if results:
            print(f"ğŸ‰ Found {len(results)} validated blogs:")
            print()
            
            for i, result in enumerate(results[:5], 1):  # Show first 5 results
                print(f"   {i}. {result['title']}")
                print(f"      URL: {result['url']}")
                print(f"      Domain: {result['domain']}")
                print(f"      DA: {result.get('domain_authority', 'N/A')}")
                print(f"      PA: {result.get('page_authority', 'N/A')}")
                print(f"      Quality Score: {result.get('content_quality_score', 'N/A')}")
                print(f"      Category: {result.get('category', 'N/A')}")
                print(f"      Comment Opportunities: {len(result.get('comment_opportunities', []))}")
                print(f"      Source: {result.get('discovery_source', 'unknown')}")
                print()
            
            if len(results) > 5:
                print(f"   ... and {len(results) - 5} more results")
        else:
            print("âŒ No results found")
    else:
        print(f"âŒ Research failed with status: {progress['status'] if progress else 'unknown'}")
    
    print()
    print("ğŸ§¹ Cleaning up...")
    blog_scraper.cleanup_old_tasks(max_age_hours=0)  # Clean up immediately for testing
    
    print("âœ… Test completed!")

async def test_rate_limiting():
    """Test the rate limiting functionality"""
    
    print("ğŸš€ Testing Rate Limiting")
    print("=" * 30)
    
    from services.scraping.rate_limiter import RateLimiter
    
    rate_limiter = RateLimiter()
    
    # Test getting status
    print("ğŸ“Š Rate Limit Status:")
    status = rate_limiter.get_all_status()
    for service, info in status.items():
        print(f"   {service}: {info['requests_remaining']}/{info['rate_limit']} remaining")
    
    print()
    print("â±ï¸  Testing rate limiting...")
    
    # Test waiting for rate limit
    import time
    start_time = time.time()
    await rate_limiter.wait_if_needed('search_engines')
    await rate_limiter.wait_if_needed('search_engines')
    end_time = time.time()
    
    print(f"   Two requests took {end_time - start_time:.2f} seconds")
    print("âœ… Rate limiting test completed!")

async def main():
    """Main test function"""
    
    try:
        # Test rate limiting first (quick test)
        await test_rate_limiting()
        print()
        
        # Test blog scraping (longer test)
        await test_blog_scraping()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Test interrupted by user")
    except Exception as e:
        print(f"\nâŒ Test failed with error: {str(e)}")
        logger.exception("Test failed")

if __name__ == "__main__":
    asyncio.run(main())
